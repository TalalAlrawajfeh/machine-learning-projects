{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzdoFaUAdY_C"
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.python.keras import Input, Model\n",
        "from tensorflow.python.keras.layers import Conv2D, DepthwiseConv2D, Add, BatchNormalization, ReLU, \\\n",
        "    GlobalAveragePooling2D, Dense\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def conv_block(input_layer,\n",
        "               filters,\n",
        "               kernel_size,\n",
        "               apply_activation=True):\n",
        "    output_layer = Conv2D(filters=filters,\n",
        "                          kernel_size=kernel_size,\n",
        "                          padding='same',\n",
        "                          use_bias=False,\n",
        "                          kernel_initializer='he_normal')(input_layer)\n",
        "    output_layer = BatchNormalization()(output_layer)\n",
        "    if not apply_activation:\n",
        "        return output_layer\n",
        "    return ReLU(max_value=6)(output_layer)\n",
        "\n",
        "\n",
        "def linear_bottleneck(input_layer,\n",
        "                      strides=(1, 1),\n",
        "                      expand_filters=64,\n",
        "                      squeeze_filters=16):\n",
        "    output_layer = conv_block(input_layer, expand_filters, (3, 3))\n",
        "    output_layer = DepthwiseConv2D(kernel_size=(3, 3),\n",
        "                                   strides=strides,\n",
        "                                   padding='same',\n",
        "                                   use_bias=False,\n",
        "                                   kernel_initializer='he_normal')(output_layer)\n",
        "    output_layer = BatchNormalization()(output_layer)\n",
        "    output_layer = ReLU(max_value=6)(output_layer)\n",
        "    return conv_block(output_layer, squeeze_filters, (1, 1), apply_activation=False)\n",
        "\n",
        "\n",
        "def inverted_linear_residual_block(input_layer,\n",
        "                                   strides=(1, 1),\n",
        "                                   expand_filters=64,\n",
        "                                   squeeze_filters=16):\n",
        "    output_layer = linear_bottleneck(input_layer,\n",
        "                                     strides,\n",
        "                                     expand_filters,\n",
        "                                     squeeze_filters)\n",
        "    return Add()([output_layer, input_layer])\n",
        "\n",
        "\n",
        "def stacked_inverted_linear_residual_blocks(input_layer,\n",
        "                                            strides=(1, 1),\n",
        "                                            expand_filters=64,\n",
        "                                            squeeze_filters=16):\n",
        "    output_layer = inverted_linear_residual_block(input_layer,\n",
        "                                                  strides,\n",
        "                                                  expand_filters,\n",
        "                                                  squeeze_filters)\n",
        "    return inverted_linear_residual_block(output_layer,\n",
        "                                          strides,\n",
        "                                          expand_filters,\n",
        "                                          squeeze_filters)\n",
        "\n",
        "\n",
        "def reduced_mobile_net():\n",
        "    input_layer = Input(shape=(28, 28, 1))\n",
        "\n",
        "    output_layer = linear_bottleneck(input_layer,\n",
        "                                     expand_filters=32,\n",
        "                                     squeeze_filters=16)\n",
        "    output_layer = linear_bottleneck(output_layer,\n",
        "                                     strides=(2, 2),\n",
        "                                     expand_filters=96,\n",
        "                                     squeeze_filters=24)\n",
        "    output_layer = inverted_linear_residual_block(output_layer,\n",
        "                                                  expand_filters=144,\n",
        "                                                  squeeze_filters=24)\n",
        "\n",
        "    output_layer = linear_bottleneck(output_layer,\n",
        "                                     strides=(2, 2),\n",
        "                                     expand_filters=144,\n",
        "                                     squeeze_filters=32)\n",
        "    output_layer = stacked_inverted_linear_residual_blocks(output_layer,\n",
        "                                                           expand_filters=192,\n",
        "                                                           squeeze_filters=32)\n",
        "\n",
        "    output_layer = linear_bottleneck(output_layer,\n",
        "                                     strides=(2, 2),\n",
        "                                     expand_filters=192,\n",
        "                                     squeeze_filters=64)\n",
        "    output_layer = stacked_inverted_linear_residual_blocks(output_layer,\n",
        "                                                           expand_filters=384,\n",
        "                                                           squeeze_filters=64)\n",
        "\n",
        "    embedding = GlobalAveragePooling2D()(output_layer)\n",
        "\n",
        "    predictions = Dense(units=10,\n",
        "                        kernel_initializer='glorot_normal',\n",
        "                        activation='softmax')(embedding)\n",
        "\n",
        "    return Model(inputs=input_layer, outputs=predictions)\n",
        "\n",
        "\n",
        "def pre_process(image):\n",
        "    return (image / 127.5 - 1.0).reshape(28, 28, 1)\n",
        "\n",
        "\n",
        "def to_one_hot_encoding(label):\n",
        "    encoding = [0.0] * 10\n",
        "    encoding[label] = 1.0\n",
        "    return encoding\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJxYFVnTtpfC",
        "outputId": "66b20194-762f-4693-a065-44b4c82ddd20"
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "train_images = [pre_process(image) for image in train_images]\n",
        "test_images = [pre_process(image) for image in test_images]\n",
        "\n",
        "train_labels = [to_one_hot_encoding(label) for label in train_labels]\n",
        "test_labels = [to_one_hot_encoding(label) for label in test_labels]\n",
        "\n",
        "model = reduced_mobile_net()\n",
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, 28, 28, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 28, 28, 32)   288         input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 28, 28, 32)   128         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_54 (ReLU)                 (None, 28, 28, 32)   0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_27 (DepthwiseC (None, 28, 28, 32)   288         re_lu_54[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 28, 28, 32)   128         depthwise_conv2d_27[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_55 (ReLU)                 (None, 28, 28, 32)   0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 28, 28, 16)   512         re_lu_55[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 28, 28, 16)   64          conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 28, 28, 96)   13824       batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 28, 28, 96)   384         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_56 (ReLU)                 (None, 28, 28, 96)   0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_28 (DepthwiseC (None, 14, 14, 96)   864         re_lu_56[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 14, 14, 96)   384         depthwise_conv2d_28[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_57 (ReLU)                 (None, 14, 14, 96)   0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 14, 14, 24)   2304        re_lu_57[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 14, 14, 24)   96          conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 14, 14, 144)  31104       batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 14, 14, 144)  576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_58 (ReLU)                 (None, 14, 14, 144)  0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_29 (DepthwiseC (None, 14, 14, 144)  1296        re_lu_58[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 14, 14, 144)  576         depthwise_conv2d_29[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_59 (ReLU)                 (None, 14, 14, 144)  0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 14, 14, 24)   3456        re_lu_59[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 14, 14, 24)   96          conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 14, 14, 24)   0           batch_normalization_89[0][0]     \n",
            "                                                                 batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 14, 14, 144)  31104       add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 14, 14, 144)  576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_60 (ReLU)                 (None, 14, 14, 144)  0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_30 (DepthwiseC (None, 7, 7, 144)    1296        re_lu_60[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 7, 7, 144)    576         depthwise_conv2d_30[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_61 (ReLU)                 (None, 7, 7, 144)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 32)     4608        re_lu_61[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 7, 7, 32)     128         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    55296       batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 7, 7, 192)    768         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_62 (ReLU)                 (None, 7, 7, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_31 (DepthwiseC (None, 7, 7, 192)    1728        re_lu_62[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 7, 7, 192)    768         depthwise_conv2d_31[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_63 (ReLU)                 (None, 7, 7, 192)    0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 32)     6144        re_lu_63[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 7, 7, 32)     128         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 7, 7, 32)     0           batch_normalization_95[0][0]     \n",
            "                                                                 batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    55296       add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 7, 7, 192)    768         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_64 (ReLU)                 (None, 7, 7, 192)    0           batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_32 (DepthwiseC (None, 7, 7, 192)    1728        re_lu_64[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, 7, 7, 192)    768         depthwise_conv2d_32[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_65 (ReLU)                 (None, 7, 7, 192)    0           batch_normalization_97[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 32)     6144        re_lu_65[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_98 (BatchNo (None, 7, 7, 32)     128         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 7, 7, 32)     0           batch_normalization_98[0][0]     \n",
            "                                                                 add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    55296       add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_99 (BatchNo (None, 7, 7, 192)    768         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_66 (ReLU)                 (None, 7, 7, 192)    0           batch_normalization_99[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_33 (DepthwiseC (None, 4, 4, 192)    1728        re_lu_66[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_100 (BatchN (None, 4, 4, 192)    768         depthwise_conv2d_33[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_67 (ReLU)                 (None, 4, 4, 192)    0           batch_normalization_100[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 4, 4, 64)     12288       re_lu_67[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_101 (BatchN (None, 4, 4, 64)     256         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 4, 4, 384)    221184      batch_normalization_101[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_102 (BatchN (None, 4, 4, 384)    1536        conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_68 (ReLU)                 (None, 4, 4, 384)    0           batch_normalization_102[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_34 (DepthwiseC (None, 4, 4, 384)    3456        re_lu_68[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_103 (BatchN (None, 4, 4, 384)    1536        depthwise_conv2d_34[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_69 (ReLU)                 (None, 4, 4, 384)    0           batch_normalization_103[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 4, 4, 64)     24576       re_lu_69[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_104 (BatchN (None, 4, 4, 64)     256         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 4, 4, 64)     0           batch_normalization_104[0][0]    \n",
            "                                                                 batch_normalization_101[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 4, 4, 384)    221184      add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_105 (BatchN (None, 4, 4, 384)    1536        conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_70 (ReLU)                 (None, 4, 4, 384)    0           batch_normalization_105[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_35 (DepthwiseC (None, 4, 4, 384)    3456        re_lu_70[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_106 (BatchN (None, 4, 4, 384)    1536        depthwise_conv2d_35[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_71 (ReLU)                 (None, 4, 4, 384)    0           batch_normalization_106[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 4, 4, 64)     24576       re_lu_71[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_107 (BatchN (None, 4, 4, 64)     256         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 4, 4, 64)     0           batch_normalization_107[0][0]    \n",
            "                                                                 add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_3 (Glo (None, 64)           0           add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 10)           650         global_average_pooling2d_3[0][0] \n",
            "==================================================================================================\n",
            "Total params: 801,162\n",
            "Trainable params: 793,418\n",
            "Non-trainable params: 7,744\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2WVf6WNtvbJ",
        "outputId": "f8f8e41f-c608-4189-b28b-a474b835ea01"
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.categorical_crossentropy,\n",
        "              metrics=[tf.keras.metrics.categorical_accuracy])\n",
        "\n",
        "model.fit(x=np.array(train_images),\n",
        "          y=np.array(train_labels),\n",
        "          validation_data=(np.array(test_images),\n",
        "                          np.array(test_labels)),\n",
        "          batch_size=128,\n",
        "          validation_batch_size=1024,\n",
        "          epochs=20)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "469/469 [==============================] - 45s 91ms/step - loss: 0.3892 - categorical_accuracy: 0.8697 - val_loss: 6.0531 - val_categorical_accuracy: 0.1135\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 42s 89ms/step - loss: 0.0347 - categorical_accuracy: 0.9890 - val_loss: 0.0312 - val_categorical_accuracy: 0.9901\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 42s 89ms/step - loss: 0.0207 - categorical_accuracy: 0.9935 - val_loss: 0.0877 - val_categorical_accuracy: 0.9751\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 42s 89ms/step - loss: 0.0176 - categorical_accuracy: 0.9947 - val_loss: 0.0659 - val_categorical_accuracy: 0.9831\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 42s 89ms/step - loss: 0.0148 - categorical_accuracy: 0.9955 - val_loss: 0.0757 - val_categorical_accuracy: 0.9794\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 42s 89ms/step - loss: 0.0177 - categorical_accuracy: 0.9941 - val_loss: 0.0393 - val_categorical_accuracy: 0.9891\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 42s 89ms/step - loss: 0.0135 - categorical_accuracy: 0.9957 - val_loss: 0.0364 - val_categorical_accuracy: 0.9897\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 42s 89ms/step - loss: 0.0126 - categorical_accuracy: 0.9960 - val_loss: 0.0332 - val_categorical_accuracy: 0.9909\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 42s 89ms/step - loss: 0.0098 - categorical_accuracy: 0.9973 - val_loss: 0.0523 - val_categorical_accuracy: 0.9859\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 42s 89ms/step - loss: 0.0101 - categorical_accuracy: 0.9965 - val_loss: 0.0411 - val_categorical_accuracy: 0.9891\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 42s 89ms/step - loss: 0.0100 - categorical_accuracy: 0.9968 - val_loss: 0.0346 - val_categorical_accuracy: 0.9911\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 42s 89ms/step - loss: 0.0084 - categorical_accuracy: 0.9975 - val_loss: 0.0232 - val_categorical_accuracy: 0.9939\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 42s 89ms/step - loss: 0.0093 - categorical_accuracy: 0.9971 - val_loss: 0.0264 - val_categorical_accuracy: 0.9925\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 42s 89ms/step - loss: 0.0082 - categorical_accuracy: 0.9977 - val_loss: 0.0568 - val_categorical_accuracy: 0.9858\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 42s 89ms/step - loss: 0.0056 - categorical_accuracy: 0.9984 - val_loss: 0.0568 - val_categorical_accuracy: 0.9867\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 42s 89ms/step - loss: 0.0065 - categorical_accuracy: 0.9977 - val_loss: 0.0563 - val_categorical_accuracy: 0.9861\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 42s 89ms/step - loss: 0.0075 - categorical_accuracy: 0.9974 - val_loss: 0.0402 - val_categorical_accuracy: 0.9891\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 42s 89ms/step - loss: 0.0062 - categorical_accuracy: 0.9981 - val_loss: 0.0263 - val_categorical_accuracy: 0.9940\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 42s 89ms/step - loss: 0.0040 - categorical_accuracy: 0.9986 - val_loss: 0.0425 - val_categorical_accuracy: 0.9905\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 42s 89ms/step - loss: 0.0074 - categorical_accuracy: 0.9980 - val_loss: 0.0348 - val_categorical_accuracy: 0.9918\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb8117775d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "cPLRGLPAxt-2",
        "outputId": "048fb882-619a-4c33-e0f2-86f50eaf3569"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "image = (train_images[0] + 1.0) * 127.5\n",
        "image = image.reshape(28, 28).astype(np.uint8)\n",
        "\n",
        "plt.imshow(image, plt.cm.gray)\n",
        "plt.show()\n",
        "\n",
        "predicted_label = np.argmax(model.predict(np.array([train_images[0]]))[0])\n",
        "true_label = np.argmax(train_labels[0])\n",
        "\n",
        "print(f'predicted label: {predicted_label}')\n",
        "print(f'true label: {true_label}')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "predicted label: 5\n",
            "true label: 5\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}