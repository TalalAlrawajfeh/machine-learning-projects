{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzdoFaUAdY_C"
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.python.keras import Input, Model\n",
        "from tensorflow.python.keras.layers import Conv2D, DepthwiseConv2D, Add, BatchNormalization, ReLU, \\\n",
        "    GlobalAveragePooling2D, Dense\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def conv_block(input_layer,\n",
        "               filters,\n",
        "               kernel_size,\n",
        "               apply_activation=True):\n",
        "    output_layer = Conv2D(filters=filters,\n",
        "                          kernel_size=kernel_size,\n",
        "                          padding='same',\n",
        "                          use_bias=False,\n",
        "                          kernel_initializer='he_normal')(input_layer)\n",
        "    output_layer = BatchNormalization()(output_layer)\n",
        "    if not apply_activation:\n",
        "        return output_layer\n",
        "    return ReLU(max_value=6)(output_layer)\n",
        "\n",
        "\n",
        "def linear_bottleneck(input_layer,\n",
        "                      strides=(1, 1),\n",
        "                      expand_filters=64,\n",
        "                      squeeze_filters=16):\n",
        "    output_layer = conv_block(input_layer, expand_filters, (3, 3))\n",
        "    output_layer = DepthwiseConv2D(kernel_size=(3, 3),\n",
        "                                   strides=strides,\n",
        "                                   padding='same',\n",
        "                                   use_bias=False,\n",
        "                                   kernel_initializer='he_normal')(output_layer)\n",
        "    output_layer = BatchNormalization()(output_layer)\n",
        "    output_layer = ReLU(max_value=6)(output_layer)\n",
        "    return conv_block(output_layer, squeeze_filters, (1, 1), apply_activation=False)\n",
        "\n",
        "\n",
        "def inverted_linear_residual_block(input_layer,\n",
        "                                   strides=(1, 1),\n",
        "                                   expand_filters=64,\n",
        "                                   squeeze_filters=16):\n",
        "    output_layer = linear_bottleneck(input_layer,\n",
        "                                     strides,\n",
        "                                     expand_filters,\n",
        "                                     squeeze_filters)\n",
        "    return Add()([output_layer, input_layer])\n",
        "\n",
        "\n",
        "def stacked_inverted_linear_residual_blocks(input_layer,\n",
        "                                            strides=(1, 1),\n",
        "                                            expand_filters=64,\n",
        "                                            squeeze_filters=16):\n",
        "    output_layer = inverted_linear_residual_block(input_layer,\n",
        "                                                  strides,\n",
        "                                                  expand_filters,\n",
        "                                                  squeeze_filters)\n",
        "    return inverted_linear_residual_block(output_layer,\n",
        "                                          strides,\n",
        "                                          expand_filters,\n",
        "                                          squeeze_filters)\n",
        "\n",
        "\n",
        "def reduced_mobile_net():\n",
        "    input_layer = Input(shape=(28, 28, 1))\n",
        "\n",
        "    output_layer = linear_bottleneck(input_layer,\n",
        "                                     expand_filters=32,\n",
        "                                     squeeze_filters=16)\n",
        "    output_layer = linear_bottleneck(output_layer,\n",
        "                                     strides=(2, 2),\n",
        "                                     expand_filters=96,\n",
        "                                     squeeze_filters=24)\n",
        "    output_layer = inverted_linear_residual_block(output_layer,\n",
        "                                                  expand_filters=144,\n",
        "                                                  squeeze_filters=24)\n",
        "\n",
        "    output_layer = linear_bottleneck(output_layer,\n",
        "                                     strides=(2, 2),\n",
        "                                     expand_filters=144,\n",
        "                                     squeeze_filters=32)\n",
        "    output_layer = stacked_inverted_linear_residual_blocks(output_layer,\n",
        "                                                           expand_filters=192,\n",
        "                                                           squeeze_filters=32)\n",
        "\n",
        "    output_layer = linear_bottleneck(output_layer,\n",
        "                                     strides=(2, 2),\n",
        "                                     expand_filters=192,\n",
        "                                     squeeze_filters=64)\n",
        "    output_layer = stacked_inverted_linear_residual_blocks(output_layer,\n",
        "                                                           expand_filters=384,\n",
        "                                                           squeeze_filters=64)\n",
        "\n",
        "    embedding = GlobalAveragePooling2D()(output_layer)\n",
        "\n",
        "    predictions = Dense(units=10,\n",
        "                        kernel_initializer='glorot_normal',\n",
        "                        activation='softmax')(embedding)\n",
        "\n",
        "    return Model(inputs=input_layer, outputs=predictions)\n",
        "\n",
        "\n",
        "def pre_process(image):\n",
        "    return (image / 127.5 - 1.0).reshape(28, 28, 1)\n",
        "\n",
        "\n",
        "def to_one_hot_encoding(label):\n",
        "    encoding = [0.0] * 10\n",
        "    encoding[label] = 1.0\n",
        "    return encoding\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJxYFVnTtpfC",
        "outputId": "66b20194-762f-4693-a065-44b4c82ddd20"
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "train_images = [pre_process(image) for image in train_images]\n",
        "test_images = [pre_process(image) for image in test_images]\n",
        "\n",
        "train_labels = [to_one_hot_encoding(label) for label in train_labels]\n",
        "test_labels = [to_one_hot_encoding(label) for label in test_labels]\n",
        "\n",
        "model = reduced_mobile_net()\n",
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, 28, 28, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 28, 28, 32)   288         input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 28, 28, 32)   128         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_54 (ReLU)                 (None, 28, 28, 32)   0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_27 (DepthwiseC (None, 28, 28, 32)   288         re_lu_54[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 28, 28, 32)   128         depthwise_conv2d_27[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_55 (ReLU)                 (None, 28, 28, 32)   0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 28, 28, 16)   512         re_lu_55[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 28, 28, 16)   64          conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 28, 28, 96)   13824       batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 28, 28, 96)   384         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_56 (ReLU)                 (None, 28, 28, 96)   0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_28 (DepthwiseC (None, 14, 14, 96)   864         re_lu_56[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 14, 14, 96)   384         depthwise_conv2d_28[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_57 (ReLU)                 (None, 14, 14, 96)   0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 14, 14, 24)   2304        re_lu_57[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 14, 14, 24)   96          conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 14, 14, 144)  31104       batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 14, 14, 144)  576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_58 (ReLU)                 (None, 14, 14, 144)  0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_29 (DepthwiseC (None, 14, 14, 144)  1296        re_lu_58[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 14, 14, 144)  576         depthwise_conv2d_29[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_59 (ReLU)                 (None, 14, 14, 144)  0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 14, 14, 24)   3456        re_lu_59[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 14, 14, 24)   96          conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 14, 14, 24)   0           batch_normalization_89[0][0]     \n",
            "                                                                 batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 14, 14, 144)  31104       add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 14, 14, 144)  576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_60 (ReLU)                 (None, 14, 14, 144)  0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_30 (DepthwiseC (None, 7, 7, 144)    1296        re_lu_60[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 7, 7, 144)    576         depthwise_conv2d_30[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_61 (ReLU)                 (None, 7, 7, 144)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 32)     4608        re_lu_61[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 7, 7, 32)     128         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    55296       batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 7, 7, 192)    768         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_62 (ReLU)                 (None, 7, 7, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_31 (DepthwiseC (None, 7, 7, 192)    1728        re_lu_62[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 7, 7, 192)    768         depthwise_conv2d_31[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_63 (ReLU)                 (None, 7, 7, 192)    0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 32)     6144        re_lu_63[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 7, 7, 32)     128         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 7, 7, 32)     0           batch_normalization_95[0][0]     \n",
            "                                                                 batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    55296       add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 7, 7, 192)    768         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_64 (ReLU)                 (None, 7, 7, 192)    0           batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_32 (DepthwiseC (None, 7, 7, 192)    1728        re_lu_64[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, 7, 7, 192)    768         depthwise_conv2d_32[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_65 (ReLU)                 (None, 7, 7, 192)    0           batch_normalization_97[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 32)     6144        re_lu_65[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_98 (BatchNo (None, 7, 7, 32)     128         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 7, 7, 32)     0           batch_normalization_98[0][0]     \n",
            "                                                                 add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    55296       add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_99 (BatchNo (None, 7, 7, 192)    768         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_66 (ReLU)                 (None, 7, 7, 192)    0           batch_normalization_99[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_33 (DepthwiseC (None, 4, 4, 192)    1728        re_lu_66[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_100 (BatchN (None, 4, 4, 192)    768         depthwise_conv2d_33[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_67 (ReLU)                 (None, 4, 4, 192)    0           batch_normalization_100[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 4, 4, 64)     12288       re_lu_67[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_101 (BatchN (None, 4, 4, 64)     256         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 4, 4, 384)    221184      batch_normalization_101[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_102 (BatchN (None, 4, 4, 384)    1536        conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_68 (ReLU)                 (None, 4, 4, 384)    0           batch_normalization_102[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_34 (DepthwiseC (None, 4, 4, 384)    3456        re_lu_68[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_103 (BatchN (None, 4, 4, 384)    1536        depthwise_conv2d_34[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_69 (ReLU)                 (None, 4, 4, 384)    0           batch_normalization_103[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 4, 4, 64)     24576       re_lu_69[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_104 (BatchN (None, 4, 4, 64)     256         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 4, 4, 64)     0           batch_normalization_104[0][0]    \n",
            "                                                                 batch_normalization_101[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 4, 4, 384)    221184      add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_105 (BatchN (None, 4, 4, 384)    1536        conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_70 (ReLU)                 (None, 4, 4, 384)    0           batch_normalization_105[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_35 (DepthwiseC (None, 4, 4, 384)    3456        re_lu_70[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_106 (BatchN (None, 4, 4, 384)    1536        depthwise_conv2d_35[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_71 (ReLU)                 (None, 4, 4, 384)    0           batch_normalization_106[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 4, 4, 64)     24576       re_lu_71[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_107 (BatchN (None, 4, 4, 64)     256         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 4, 4, 64)     0           batch_normalization_107[0][0]    \n",
            "                                                                 add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_3 (Glo (None, 64)           0           add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 10)           650         global_average_pooling2d_3[0][0] \n",
            "==================================================================================================\n",
            "Total params: 801,162\n",
            "Trainable params: 793,418\n",
            "Non-trainable params: 7,744\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2WVf6WNtvbJ",
        "outputId": "f8f8e41f-c608-4189-b28b-a474b835ea01"
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.categorical_crossentropy,\n",
        "              metrics=[tf.keras.metrics.categorical_accuracy])\n",
        "\n",
        "model.fit(x=np.array(train_images),\n",
        "          y=np.array(train_labels),\n",
        "          validation_data=(np.array(test_images),\n",
        "                          np.array(test_labels)),\n",
        "          batch_size=128,\n",
        "          validation_batch_size=1024,\n",
        "          epochs=20)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "469/469 [==============================] - 45s 91ms/step - loss: 0.3892 - categorical_accuracy: 0.8697 - val_loss: 6.0531 - val_categorical_accuracy: 0.1135\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 42s 89ms/step - loss: 0.0347 - categorical_accuracy: 0.9890 - val_loss: 0.0312 - val_categorical_accuracy: 0.9901\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 42s 89ms/step - loss: 0.0207 - categorical_accuracy: 0.9935 - val_loss: 0.0877 - val_categorical_accuracy: 0.9751\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 42s 89ms/step - loss: 0.0176 - categorical_accuracy: 0.9947 - val_loss: 0.0659 - val_categorical_accuracy: 0.9831\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 42s 89ms/step - loss: 0.0148 - categorical_accuracy: 0.9955 - val_loss: 0.0757 - val_categorical_accuracy: 0.9794\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 42s 89ms/step - loss: 0.0177 - categorical_accuracy: 0.9941 - val_loss: 0.0393 - val_categorical_accuracy: 0.9891\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 42s 89ms/step - loss: 0.0135 - categorical_accuracy: 0.9957 - val_loss: 0.0364 - val_categorical_accuracy: 0.9897\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 42s 89ms/step - loss: 0.0126 - categorical_accuracy: 0.9960 - val_loss: 0.0332 - val_categorical_accuracy: 0.9909\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 42s 89ms/step - loss: 0.0098 - categorical_accuracy: 0.9973 - val_loss: 0.0523 - val_categorical_accuracy: 0.9859\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 42s 89ms/step - loss: 0.0101 - categorical_accuracy: 0.9965 - val_loss: 0.0411 - val_categorical_accuracy: 0.9891\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 42s 89ms/step - loss: 0.0100 - categorical_accuracy: 0.9968 - val_loss: 0.0346 - val_categorical_accuracy: 0.9911\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 42s 89ms/step - loss: 0.0084 - categorical_accuracy: 0.9975 - val_loss: 0.0232 - val_categorical_accuracy: 0.9939\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 42s 89ms/step - loss: 0.0093 - categorical_accuracy: 0.9971 - val_loss: 0.0264 - val_categorical_accuracy: 0.9925\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 42s 89ms/step - loss: 0.0082 - categorical_accuracy: 0.9977 - val_loss: 0.0568 - val_categorical_accuracy: 0.9858\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 42s 89ms/step - loss: 0.0056 - categorical_accuracy: 0.9984 - val_loss: 0.0568 - val_categorical_accuracy: 0.9867\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 42s 89ms/step - loss: 0.0065 - categorical_accuracy: 0.9977 - val_loss: 0.0563 - val_categorical_accuracy: 0.9861\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 42s 89ms/step - loss: 0.0075 - categorical_accuracy: 0.9974 - val_loss: 0.0402 - val_categorical_accuracy: 0.9891\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 42s 89ms/step - loss: 0.0062 - categorical_accuracy: 0.9981 - val_loss: 0.0263 - val_categorical_accuracy: 0.9940\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 42s 89ms/step - loss: 0.0040 - categorical_accuracy: 0.9986 - val_loss: 0.0425 - val_categorical_accuracy: 0.9905\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 42s 89ms/step - loss: 0.0074 - categorical_accuracy: 0.9980 - val_loss: 0.0348 - val_categorical_accuracy: 0.9918\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb8117775d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    }
  ]
}