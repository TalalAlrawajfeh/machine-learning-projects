{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzdoFaUAdY_C"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.python.keras import Input, Model\n",
        "from tensorflow.python.keras.layers import Conv2D, BatchNormalization, ReLU, Dense, MaxPooling2D, Add, \\\n",
        "    GlobalAveragePooling2D\n",
        "\n",
        "\n",
        "def conv_block(input_layer,\n",
        "               filters,\n",
        "               kernel_size,\n",
        "               strides=(1, 1),\n",
        "               apply_activation=True):\n",
        "    output_layer = Conv2D(filters=filters,\n",
        "                          kernel_size=kernel_size,\n",
        "                          strides=strides,\n",
        "                          padding='same',\n",
        "                          use_bias=False,\n",
        "                          kernel_initializer='he_normal')(input_layer)\n",
        "    output_layer = BatchNormalization()(output_layer)\n",
        "    if not apply_activation:\n",
        "        return output_layer\n",
        "    return ReLU()(output_layer)\n",
        "\n",
        "\n",
        "def resnet_module(input_layer,\n",
        "                  filters):\n",
        "    output_layer = conv_block(input_layer, filters, (3, 3))\n",
        "    output_layer = conv_block(output_layer, filters, (3, 3), apply_activation=False)\n",
        "    output_layer = Add()([input_layer, output_layer])\n",
        "    return ReLU()(output_layer)\n",
        "\n",
        "\n",
        "def transition_layer(input_layer,\n",
        "                     filters):\n",
        "    output_layer1 = conv_block(input_layer, filters, (3, 3), (2, 2))\n",
        "    output_layer2 = conv_block(input_layer, filters, (3, 3), (2, 2))\n",
        "    output_layer = Add()([output_layer1, output_layer2])\n",
        "    return ReLU()(output_layer)\n",
        "\n",
        "\n",
        "def reduced_resnet():\n",
        "    input_layer = Input(shape=(28, 28, 1))\n",
        "\n",
        "    output_layer = conv_block(input_layer, 16, (3, 3))\n",
        "    output_layer = conv_block(output_layer, 16, (3, 3))\n",
        "    output_layer = MaxPooling2D(pool_size=(3, 3),\n",
        "                                strides=(2, 2))(output_layer)\n",
        "\n",
        "    output_layer = resnet_module(output_layer, 16)\n",
        "    output_layer = resnet_module(output_layer, 16)\n",
        "    output_layer = resnet_module(output_layer, 16)\n",
        "\n",
        "    output_layer = transition_layer(output_layer, 32)\n",
        "\n",
        "    output_layer = resnet_module(output_layer, 32)\n",
        "    output_layer = resnet_module(output_layer, 32)\n",
        "    output_layer = resnet_module(output_layer, 32)\n",
        "\n",
        "    output_layer = transition_layer(output_layer, 64)\n",
        "\n",
        "    output_layer = resnet_module(output_layer, 64)\n",
        "    output_layer = resnet_module(output_layer, 64)\n",
        "    output_layer = resnet_module(output_layer, 64)\n",
        "\n",
        "    embedding = GlobalAveragePooling2D()(output_layer)\n",
        "\n",
        "    predictions = Dense(units=128,\n",
        "                        kernel_initializer='he_normal',\n",
        "                        use_bias=False)(embedding)\n",
        "    predictions = BatchNormalization()(predictions)\n",
        "    predictions = ReLU()(predictions)\n",
        "\n",
        "    predictions = Dense(units=10,\n",
        "                        kernel_initializer='glorot_normal',\n",
        "                        activation='softmax')(predictions)\n",
        "\n",
        "    return Model(inputs=input_layer, outputs=predictions)\n",
        "\n",
        "\n",
        "def pre_process(image):\n",
        "    return (image / 127.5 - 1.0).reshape(28, 28, 1)\n",
        "\n",
        "\n",
        "def to_one_hot_encoding(label):\n",
        "    encoding = [0.0] * 10\n",
        "    encoding[label] = 1.0\n",
        "    return encoding\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJxYFVnTtpfC",
        "outputId": "32e20f94-3045-4662-e358-a04d4a0db92e"
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "train_images = [pre_process(image) for image in train_images]\n",
        "test_images = [pre_process(image) for image in test_images]\n",
        "\n",
        "train_labels = [to_one_hot_encoding(label) for label in train_labels]\n",
        "test_labels = [to_one_hot_encoding(label) for label in test_labels]\n",
        "\n",
        "model = reduced_resnet()\n",
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 28, 28, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 28, 28, 16)   144         input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 28, 28, 16)   64          conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_42 (ReLU)                 (None, 28, 28, 16)   0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 28, 28, 16)   2304        re_lu_42[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 28, 28, 16)   64          conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_43 (ReLU)                 (None, 28, 28, 16)   0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 13, 13, 16)   0           re_lu_43[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 13, 13, 16)   2304        max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 13, 13, 16)   64          conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_44 (ReLU)                 (None, 13, 13, 16)   0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 13, 13, 16)   2304        re_lu_44[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 13, 13, 16)   64          conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 13, 13, 16)   0           max_pooling2d_4[0][0]            \n",
            "                                                                 batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_45 (ReLU)                 (None, 13, 13, 16)   0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 13, 13, 16)   2304        re_lu_45[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 13, 13, 16)   64          conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_46 (ReLU)                 (None, 13, 13, 16)   0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 13, 13, 16)   2304        re_lu_46[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 13, 13, 16)   64          conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 13, 13, 16)   0           re_lu_45[0][0]                   \n",
            "                                                                 batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_47 (ReLU)                 (None, 13, 13, 16)   0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 13, 13, 16)   2304        re_lu_47[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 13, 13, 16)   64          conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_48 (ReLU)                 (None, 13, 13, 16)   0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 13, 13, 16)   2304        re_lu_48[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 13, 13, 16)   64          conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 13, 13, 16)   0           re_lu_47[0][0]                   \n",
            "                                                                 batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_49 (ReLU)                 (None, 13, 13, 16)   0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 32)     4608        re_lu_49[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 32)     4608        re_lu_49[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 32)     128         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 32)     128         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_50 (ReLU)                 (None, 7, 7, 32)     0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_51 (ReLU)                 (None, 7, 7, 32)     0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 7, 7, 32)     0           re_lu_50[0][0]                   \n",
            "                                                                 re_lu_51[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_52 (ReLU)                 (None, 7, 7, 32)     0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 32)     9216        re_lu_52[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 32)     128         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_53 (ReLU)                 (None, 7, 7, 32)     0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 32)     9216        re_lu_53[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 32)     128         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 7, 7, 32)     0           re_lu_52[0][0]                   \n",
            "                                                                 batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_54 (ReLU)                 (None, 7, 7, 32)     0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 32)     9216        re_lu_54[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 32)     128         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_55 (ReLU)                 (None, 7, 7, 32)     0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 32)     9216        re_lu_55[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 32)     128         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 7, 7, 32)     0           re_lu_54[0][0]                   \n",
            "                                                                 batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_56 (ReLU)                 (None, 7, 7, 32)     0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 32)     9216        re_lu_56[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 32)     128         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_57 (ReLU)                 (None, 7, 7, 32)     0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 32)     9216        re_lu_57[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 32)     128         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 7, 7, 32)     0           re_lu_56[0][0]                   \n",
            "                                                                 batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_58 (ReLU)                 (None, 7, 7, 32)     0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 4, 4, 64)     18432       re_lu_58[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 4, 4, 64)     18432       re_lu_58[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 4, 4, 64)     256         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 4, 4, 64)     256         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_59 (ReLU)                 (None, 4, 4, 64)     0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_60 (ReLU)                 (None, 4, 4, 64)     0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 4, 4, 64)     0           re_lu_59[0][0]                   \n",
            "                                                                 re_lu_60[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_61 (ReLU)                 (None, 4, 4, 64)     0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 4, 4, 64)     36864       re_lu_61[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 4, 4, 64)     256         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_62 (ReLU)                 (None, 4, 4, 64)     0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 4, 4, 64)     36864       re_lu_62[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 4, 4, 64)     256         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 4, 4, 64)     0           re_lu_61[0][0]                   \n",
            "                                                                 batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_63 (ReLU)                 (None, 4, 4, 64)     0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 4, 4, 64)     36864       re_lu_63[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 4, 4, 64)     256         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_64 (ReLU)                 (None, 4, 4, 64)     0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 4, 4, 64)     36864       re_lu_64[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 4, 4, 64)     256         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 4, 4, 64)     0           re_lu_63[0][0]                   \n",
            "                                                                 batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_65 (ReLU)                 (None, 4, 4, 64)     0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 4, 4, 64)     36864       re_lu_65[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 4, 4, 64)     256         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_66 (ReLU)                 (None, 4, 4, 64)     0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 4, 4, 64)     36864       re_lu_66[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 4, 4, 64)     256         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 4, 4, 64)     0           re_lu_65[0][0]                   \n",
            "                                                                 batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_67 (ReLU)                 (None, 4, 4, 64)     0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 64)           0           re_lu_67[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 128)          8192        global_average_pooling2d_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 128)          512         dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_68 (ReLU)                 (None, 128)          0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 10)           1290        re_lu_68[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 352,410\n",
            "Trainable params: 350,362\n",
            "Non-trainable params: 2,048\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2WVf6WNtvbJ",
        "outputId": "a9dc796c-07aa-4958-aee8-7d728fef028f"
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.categorical_crossentropy,\n",
        "              metrics=[tf.keras.metrics.categorical_accuracy])\n",
        "\n",
        "model.fit(x=np.array(train_images),\n",
        "          y=np.array(train_labels),\n",
        "          validation_data=(np.array(test_images),\n",
        "                          np.array(test_labels)),\n",
        "          batch_size=128,\n",
        "          validation_batch_size=1024,\n",
        "          epochs=20)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "469/469 [==============================] - 10s 17ms/step - loss: 0.3655 - categorical_accuracy: 0.8885 - val_loss: 0.0806 - val_categorical_accuracy: 0.9749\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.0434 - categorical_accuracy: 0.9874 - val_loss: 0.1062 - val_categorical_accuracy: 0.9663\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.0280 - categorical_accuracy: 0.9914 - val_loss: 0.0831 - val_categorical_accuracy: 0.9735\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.0260 - categorical_accuracy: 0.9923 - val_loss: 0.1132 - val_categorical_accuracy: 0.9663\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.0218 - categorical_accuracy: 0.9932 - val_loss: 0.0567 - val_categorical_accuracy: 0.9839\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.0172 - categorical_accuracy: 0.9947 - val_loss: 0.0444 - val_categorical_accuracy: 0.9880\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.0163 - categorical_accuracy: 0.9951 - val_loss: 0.0415 - val_categorical_accuracy: 0.9882\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.0132 - categorical_accuracy: 0.9957 - val_loss: 0.0544 - val_categorical_accuracy: 0.9844\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.0107 - categorical_accuracy: 0.9966 - val_loss: 0.0389 - val_categorical_accuracy: 0.9882\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.0111 - categorical_accuracy: 0.9963 - val_loss: 0.0392 - val_categorical_accuracy: 0.9886\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.0094 - categorical_accuracy: 0.9971 - val_loss: 0.2664 - val_categorical_accuracy: 0.9333\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.0109 - categorical_accuracy: 0.9965 - val_loss: 0.0613 - val_categorical_accuracy: 0.9807\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.0096 - categorical_accuracy: 0.9968 - val_loss: 0.0711 - val_categorical_accuracy: 0.9831\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.0074 - categorical_accuracy: 0.9977 - val_loss: 0.1004 - val_categorical_accuracy: 0.9749\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.0087 - categorical_accuracy: 0.9974 - val_loss: 0.0271 - val_categorical_accuracy: 0.9922\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.0067 - categorical_accuracy: 0.9980 - val_loss: 0.0376 - val_categorical_accuracy: 0.9907\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.0060 - categorical_accuracy: 0.9980 - val_loss: 0.0309 - val_categorical_accuracy: 0.9908\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.0081 - categorical_accuracy: 0.9975 - val_loss: 0.0366 - val_categorical_accuracy: 0.9899\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.0058 - categorical_accuracy: 0.9981 - val_loss: 0.0406 - val_categorical_accuracy: 0.9880\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.0030 - categorical_accuracy: 0.9992 - val_loss: 0.0698 - val_categorical_accuracy: 0.9836\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6de60625d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "cPLRGLPAxt-2",
        "outputId": "13e6479e-0799-4694-f557-b1b6dff13ff5"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "image = (train_images[0] + 1.0) * 127.5\n",
        "image = image.reshape(28, 28).astype(np.uint8)\n",
        "\n",
        "plt.imshow(image, plt.cm.gray)\n",
        "plt.show()\n",
        "\n",
        "predicted_label = np.argmax(model.predict(np.array([train_images[0]]))[0])\n",
        "true_label = np.argmax(train_labels[0])\n",
        "\n",
        "print(f'predicted label: {predicted_label}')\n",
        "print(f'true label: {true_label}')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "predicted label: 5\n",
            "true label: 5\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}